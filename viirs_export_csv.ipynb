{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"viirs_export_csv.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oYM01t0D4gLJ"},"source":["\n","**Module:** viirs_export_csv.ipynb\n","\n","**Disclaimer**: The code is for demonstration purposes only. Users are responsible to check for accuracy and revise to fit their objective.\n","\n","**Organization**: NASA ARSET\n","\n","**Author**: Justin Roberts-Pierel and Pawan Gupta, 2015.\n","\n","**Modified to work with netCDF** : Vikalp Mishra, 2019 \n","\n","**Modified to work with VIIRS data**: Aavash Thapa, 2020\n","\n","**Modified**: Pawan Gupta, September 28 2021 to work with VIIRS DT data\n","\n","**Purpose**: To save data into a csv file from a VIIRS Deep Blue netcdf4 file\n"]},{"cell_type":"code","metadata":{"id":"Nv3UhsBrKaNW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632840267718,"user_tz":300,"elapsed":43046,"user":{"displayName":"Pawan Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimbFsz3Li7BkySX80fXswRhtvBp2BifgIyWxXnzg=s64","userId":"05790015480825390149"}},"outputId":"ae6e4f24-2e08-4328-ab7b-9778731b212c"},"source":["#Mount drive to save files there\n","#clone the repository to access files from there\n","#pull the latest\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","! git clone https://github.com/pawanpgupta/DTAerosols.git\n","! git -C DTAerosols/ pull"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Cloning into 'DTAerosols'...\n","remote: Enumerating objects: 18, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (16/16), done.\u001b[K\n","remote: Total 18 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (18/18), done.\n","Already up to date.\n"]}]},{"cell_type":"code","metadata":{"id":"YTxkRB897HJ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632840271860,"user_tz":300,"elapsed":4148,"user":{"displayName":"Pawan Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimbFsz3Li7BkySX80fXswRhtvBp2BifgIyWxXnzg=s64","userId":"05790015480825390149"}},"outputId":"ba82db63-a4d2-42ef-fade-68890e9a11fe"},"source":["! pip install netCDF4\n","from netCDF4 import Dataset\n","import numpy as np\n","import sys\n","import time\n","import calendar\n","import datetime as dt\n","import pandas as pd"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: netCDF4 in /usr/local/lib/python3.7/dist-packages (1.5.7)\n","Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netCDF4) (1.5.0)\n","Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.7/dist-packages (from netCDF4) (1.19.5)\n"]}]},{"cell_type":"code","metadata":{"id":"Wpy4FnpQvFtI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632842338198,"user_tz":300,"elapsed":4251,"user":{"displayName":"Pawan Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimbFsz3Li7BkySX80fXswRhtvBp2BifgIyWxXnzg=s64","userId":"05790015480825390149"}},"outputId":"5062e578-5d1e-4655-dffb-8127ecb107ca"},"source":["\n","#!/usr/bin/python      \n","\n","#This finds the user's current path so that all hdf4 files can be found\n","try:\n","    fileList = open('DTAerosols/fileList.txt', 'r')\n","\n","except:\n","    print('Did not find a text file containing file names (perhaps name does not match)')\n","    sys.exit()\n","\n","#loops through all files listed in the text file\n","for FILE_NAME in fileList:\n","    FILE_NAME=FILE_NAME.strip()\n","    user_input=input('\\nWould you like to process\\n' + FILE_NAME + '\\n\\n(Y/N)')\n","    if (user_input == 'N' or user_input == 'n'):\n","        print('Skipping...')\n","        continue\n","    else:\n","        file = Dataset('DTAerosols/' + FILE_NAME, 'r')\n","# read the data\n","        if 'AERDT' in FILE_NAME:\n","            print('This is a VIIRS Dark Target file.')\n","            #this is how you access the data tree in an hdf5 file\n","            SDS_NAME='Optical_Depth_Land_And_Ocean'    \n","        ds=file  \n","        grp='/geolocation_data/'\n","        geods = ds[grp]\n","        lat= geods.variables['latitude'][:][:]\n","        lon= geods.variables['longitude'][:][:]\n","        grp='/geophysical_data/'\n","        geods = ds[grp]\n","        data = geods.variables[SDS_NAME]\n","        ds=geods\n","        vlist = [var for var in ds.variables] \n","\n","        #get necessary attributes \n","        fv=data._FillValue\n","          \n","        fileparts=FILE_NAME.split('.')\n","\n","        #There are some columns that are going to be the same\n","        #like the year, month and so on listed below.\n","        #Therefore, we can make the columns for them to store\n","        #the data for every row.\n","        year = np.zeros(lat.shape)\n","        mth = np.zeros(lat.shape)\n","        doy = np.zeros(lat.shape)\n","        hr = np.zeros(lat.shape)\n","        mn = np.zeros(lat.shape)\n","        \n","        for i in range(0,lat.shape[0]):\n","            y= fileparts[1][1:5]\n","            h = fileparts[2][0:2]\n","            m = fileparts[2][2:4]\n","            date = y + ',' + fileparts[1][5:8] + ',' + h + ',' + m\n","            t2 = dt.datetime.strptime(date,'%Y,%j,%H,%M')\n","           \n","            mt = t2.month\n","            d = t2.day\n","            \n","            year[i][:] = y\n","            mth[i][:] = mt\n","            doy[i][:] = d\n","            hr[i][:] = h\n","            mn[i][:] = m\n","       \n","        #create the dataframe and enter the values here\n","        df = pd.DataFrame()\n","        df['Year'] = year.ravel()\n","        df['Month'] = mth.ravel()\n","        df['Day'] = doy.ravel()\n","        df['Hour'] = hr.ravel()\n","        df['Minute'] = mn.ravel()\n","        \n","        #0-->Aerosol_Optical_Thickness_550_Land\n","        #3-->Aerosol_Optical_Thickness_550_Land_Ocean_Best_Estimate\n","        #8-->Aerosol_Optical_Thickness_QA_Flag_Land\n","        #11-->Aerosol_Type_Land_Ocean\n","        #18-->Angstrom_Exponent_Land_Ocean_Best_Estimate\n","        sds_lst = ['Image_Optical_Depth_Land_And_Ocean',\n","                   'Optical_Depth_Land_And_Ocean',\n","                   'Land_Ocean_Quality_Flag',\n","                   'Land_Sea_Flag', 'Angstrom_Exponent_1_Ocean']\n","        \n","        #This for loop saves all of the SDS in the dictionary at the top (dependent on file type) to the array (with titles)\n","        #All the sds that we need seem to be contained in this range.\n","        #Can extend this range to loop through more sds variables in the NC file.\n","        for i in range(0,30):\n","            SDS_NAME=vlist[(i)] # The name of the sds to read\n","            if SDS_NAME in sds_lst:\n","                print('SDS_NAME', SDS_NAME)\n","                #try:\n","                sds=geods.variables[SDS_NAME]\n","               \n","                scale = 1.0\n","                fv=sds._FillValue\n","                #get SDS data as a vector\n","                data=sds[:].ravel()\n","               #The next few lines change fill value/missing value to NaN so that we can multiply valid values by the scale factor, then back to fill values for saving\n","                data=data.astype(float)\n","                data=(data)*scale  \n","                data[np.isnan(data)]=fv\n","                data[data==float(fv)]=np.nan\n","                data=np.array(data[:])\n","                df[SDS_NAME] = data\n","    \n","    outfilename=FILE_NAME[:-3]+'.csv'    \n","    df.to_csv(\"drive/My Drive/Colab Notebooks/\" + outfilename, index = False) \n","    print('\\nAll files have been saved successfully.')"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Would you like to process\n","AERDT_L2_VIIRS_SNPP.A2021269.2042.011.2021270073049.nc\n","\n","(Y/N)y\n","This is a VIIRS Dark Target file.\n","SDS_NAME Angstrom_Exponent_1_Ocean\n","SDS_NAME Image_Optical_Depth_Land_And_Ocean\n","SDS_NAME Land_Ocean_Quality_Flag\n","SDS_NAME Land_Sea_Flag\n","SDS_NAME Optical_Depth_Land_And_Ocean\n","\n","All files have been saved successfully.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRjH9qy67Vyl","executionInfo":{"status":"ok","timestamp":1632841677110,"user_tz":300,"elapsed":169,"user":{"displayName":"Pawan Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimbFsz3Li7BkySX80fXswRhtvBp2BifgIyWxXnzg=s64","userId":"05790015480825390149"}},"outputId":"b589e289-aa58-41f5-fdca-162296c95298"},"source":["vlist"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Aerosol_Cldmask_Land_Ocean',\n"," 'Aerosol_Cloud_Fraction_Land',\n"," 'Aerosol_Cloud_Fraction_Ocean',\n"," 'Aerosol_Type_Land',\n"," 'Angstrom_Exponent_1_Ocean',\n"," 'Angstrom_Exponent_2_Ocean',\n"," 'Asymmetry_Factor_Average_Ocean',\n"," 'Average_Cloud_Pixel_Distance_Land_Ocean',\n"," 'Backscattering_Ratio_Average_Ocean',\n"," 'Cloud_Pixel_Distance_Land_Ocean',\n"," 'Corrected_Optical_Depth_Land',\n"," 'Effective_Optical_Depth_Average_Ocean',\n"," 'Effective_Radius_Ocean',\n"," 'Error_Flag_Land_And_Ocean',\n"," 'Fitting_Error_Land',\n"," 'Image_Optical_Depth_Land_And_Ocean',\n"," 'Land_Ocean_Quality_Flag',\n"," 'Land_Sea_Flag',\n"," 'Least_Squares_Error_Ocean',\n"," 'Mass_Concentration_Land',\n"," 'Mass_Concentration_Ocean',\n"," 'Mean_Reflectance_Land',\n"," 'Mean_Reflectance_Ocean',\n"," 'Number_Pixels_Used_Land',\n"," 'Number_Pixels_Used_Ocean',\n"," 'Optical_Depth_By_Models_Ocean',\n"," 'Optical_Depth_Land_And_Ocean',\n"," 'Optical_Depth_Large_Average_Ocean',\n"," 'Optical_Depth_Ratio_Small_Land',\n"," 'Optical_Depth_Ratio_Small_Ocean_0p55micron',\n"," 'Optical_Depth_Small_Average_Ocean',\n"," 'PSML003_Ocean',\n"," 'STD_Reflectance_Land',\n"," 'STD_Reflectance_Ocean',\n"," 'Surface_Reflectance_Land',\n"," 'Topographic_Altitude_Land',\n"," 'Wind_Speed_Ncep_Ocean']"]},"metadata":{},"execution_count":29}]}]}